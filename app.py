import streamlit as st
import json
import pandas as pd
import os
import re

# --------------------------------------------------------------------------
# 1. í˜ì´ì§€ ì„¤ì • ë° ë””ìì¸
# --------------------------------------------------------------------------
st.set_page_config(page_title="ë²•ë¥  ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì‹œìŠ¤í…œ", layout="wide", page_icon="âš–ï¸")

st.title("âš–ï¸ ê¸°ì—… ë§ì¶¤í˜• ë²•ë¥  ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì‹œìŠ¤í…œ")
st.markdown("##### ğŸš€ GraphRAG ê¸°ë°˜ ë²•ë¥  ì¤€ìˆ˜(Compliance) ì§€ì› ì†”ë£¨ì…˜")
st.markdown("---")

# --------------------------------------------------------------------------
# 2. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
# --------------------------------------------------------------------------
@st.cache_data
def load_data():
    file_name = 'Law_Graph_Final_v4_risk_propagated.json'
    if not os.path.exists(file_name):
        return None, None
    
    with open(file_name, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    nodes = data.get('nodes', [])
    edges = data.get('edges', [])
    
    df = pd.DataFrame(nodes)
    
    # ARTICLE(ì¡°í•­)ë§Œ ë‚¨ê¸°ê¸° ë° ì—ëŸ¬ ë°©ì§€ìš© ì»¬ëŸ¼ ì²´í¬
    if 'node_type' in df.columns:
        df = df[df['node_type'] == 'ARTICLE']
    else:
        # node_typeì´ ì•„ì˜ˆ ì—†ìœ¼ë©´ ë¹ˆ ë°ì´í„°í”„ë ˆì„ ë°˜í™˜
        return pd.DataFrame(), []
    
    # ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ì•ˆì „í•˜ê²Œ)
    if 'risk_level_final' not in df.columns:
        df['risk_level_final'] = 'LOW'
    if 'risk_evidence' not in df.columns:
        df['risk_evidence'] = ''
    if 'law_name' not in df.columns:
        df['law_name'] = ''
    if 'content' not in df.columns:
        df['content'] = ''
        
    return df, edges

nodes_df, edges_data = load_data()

# --------------------------------------------------------------------------
# 3. ì‚¬ì´ë“œë°”: ê¸°ì—… í”„ë¡œí•„ ì„¤ì •
# --------------------------------------------------------------------------
st.sidebar.header("ğŸ¢ ê¸°ì—… ìƒì„¸ í”„ë¡œí•„")

# [ì„¤ì • 1] ì—…ì¢… ì„ íƒ
industry_map = {
    "ê±´ì„¤ì—…": ["ê±´ì„¤ê¸°ê³„ê´€ë¦¬ë²•", "ê±´ì„¤ê¸°ìˆ  ì§„í¥ë²•", "ê±´ì„¤ì‚°ì—…ê¸°ë³¸ë²•", "ì‚°ì—…ì•ˆì „ë³´ê±´ë²•"],
    "ì œì¡°ì—…": ["ì‚°ì—…ì•ˆì „ë³´ê±´ë²•", "ëŒ€ê¸°í™˜ê²½ë³´ì „ë²•", "íê¸°ë¬¼ê´€ë¦¬ë²•", "ê³ ì••ê°€ìŠ¤ ì•ˆì „ê´€ë¦¬ë²•"],
    "í™˜ê²½/ì—ë„ˆì§€": ["ëŒ€ê¸°í™˜ê²½ë³´ì „ë²•", "íê¸°ë¬¼ê´€ë¦¬ë²•", "ì†Œë°©ê¸°ë³¸ë²•"]
}
industry_options = ["ì „ì²´ ë³´ê¸°"] + list(industry_map.keys())
selected_industry = st.sidebar.selectbox("1. ì—…ì¢… (Industry)", industry_options)

# [ì„¤ì • 2] ê¸°ì—… ê·œëª¨
st.sidebar.markdown("---")
size_options = ["ì „ì²´ ë³´ê¸°", "5ì¸ ë¯¸ë§Œ", "5ì¸ ì´ìƒ ~ 50ì¸ ë¯¸ë§Œ", "50ì¸ ì´ìƒ ~ 300ì¸ ë¯¸ë§Œ", "300ì¸ ì´ìƒ"]
company_size = st.sidebar.selectbox("2. ê¸°ì—… ê·œëª¨ (ìƒì‹œ ê·¼ë¡œì ìˆ˜)", size_options)
st.sidebar.caption("â€» í˜„ì¬ ë°ì´í„°ì—ëŠ” ê¸°ì—… ê·œëª¨ë³„ ì ìš© ì—¬ë¶€ê°€ í¬í•¨ë˜ì–´ ìˆì§€ ì•Šì•„, ì´ í•­ëª©ì€ ì°¸ê³ ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.")

# [ì„¤ì • 3] ë³´ìœ  ì„¤ë¹„ (í‚¤ì›Œë“œ ë§¤í•‘)
st.sidebar.markdown("---")
# ì„¤ë¹„ì™€ ê´€ë ¨ëœ í‚¤ì›Œë“œ ì •ì˜ (ì´ ë‹¨ì–´ê°€ ë³¸ë¬¸ì— ìˆìœ¼ë©´ í•„í„°ë§)
equipment_keyword_map = {
    "í¬ë ˆì¸/ë¦¬í”„íŠ¸": ["í¬ë ˆì¸", "ë¦¬í”„íŠ¸", "ê¸°ì¤‘ê¸°", "ìŠ¹ê°•ê¸°"],
    "ì§€ê²Œì°¨": ["ì§€ê²Œì°¨", "ìš´ë°˜"],
    "ì••ë ¥ìš©ê¸°": ["ì••ë ¥ìš©ê¸°", "ê³ ì••ê°€ìŠ¤", "ì €ì¥íƒ±í¬"],
    "ì†Œê°ì‹œì„¤": ["ì†Œê°", "ì—°ì†Œ", "ë°°ì¶œ"],
    "í™”í•™ë¬¼ì§ˆ ì €ì¥ì†Œ": ["í™”í•™ë¬¼ì§ˆ", "ìœ í•´ë¬¼ì§ˆ", "ì €ì¥ì†Œ", "ë³´ê´€"]
}
equipment_options = list(equipment_keyword_map.keys())
selected_equipment = st.sidebar.multiselect("3. ë³´ìœ  ì„¤ë¹„ (ê´€ë ¨ ì¡°í•­ ê²€ìƒ‰)", equipment_options)

# [ì„¤ì • 4] ìœ„í—˜ë„ í•„í„°
st.sidebar.markdown("---")
risk_options = ["HIGH", "MEDIUM", "LOW"]
selected_risks = st.sidebar.multiselect(
    "ì¡°íšŒí•  ìœ„í—˜ ë“±ê¸‰", 
    risk_options, 
    default=["HIGH", "MEDIUM"]
)

# [ì„¤ì • 5] ê²€ìƒ‰
search_query = st.sidebar.text_input("ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰")


# --------------------------------------------------------------------------
# 4. í•„í„°ë§ ë¡œì§ ì—”ì§„
# --------------------------------------------------------------------------
if nodes_df is not None and not nodes_df.empty:
    filtered_df = nodes_df.copy()

    # [1] ì—…ì¢… í•„í„° (ë²•ë ¹ ì´ë¦„ ê¸°ì¤€)
    if selected_industry != "ì „ì²´ ë³´ê¸°":
        target_laws = industry_map.get(selected_industry, [])
        if target_laws:
            filtered_df = filtered_df[filtered_df['law_name'].str.contains('|'.join(target_laws), na=False)]

    # [2] ë³´ìœ  ì„¤ë¹„ í•„í„° (ë³¸ë¬¸ ë‚´ìš© ê¸°ì¤€ - ì—¬ê¸°ê°€ í•µì‹¬!)
    # ì„¤ë¹„ë¥¼ ì„ íƒí–ˆì„ ë•Œë§Œ ë¡œì§ì´ ë•ë‹ˆë‹¤.
    if selected_equipment:
        # ì„ íƒëœ ì„¤ë¹„ë“¤ì˜ ëª¨ë“  í‚¤ì›Œë“œë¥¼ í•˜ë‚˜ë¡œ í•©ì¹©ë‹ˆë‹¤.
        # ì˜ˆ: í¬ë ˆì¸ ì„ íƒ -> ["í¬ë ˆì¸", "ë¦¬í”„íŠ¸", "ê¸°ì¤‘ê¸°", "ìŠ¹ê°•ê¸°"]
        target_keywords = []
        for eq in selected_equipment:
            target_keywords.extend(equipment_keyword_map.get(eq, []))
        
        # í‚¤ì›Œë“œ ì¤‘ í•˜ë‚˜ë¼ë„ ë³¸ë¬¸ì— í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ì¶”ì¶œ
        if target_keywords:
            keyword_pattern = '|'.join(target_keywords)
            filtered_df = filtered_df[filtered_df['content'].str.contains(keyword_pattern, na=False)]

    # [3] ìœ„í—˜ë„ í•„í„°
    if selected_risks:
        filtered_df = filtered_df[filtered_df['risk_level_final'].isin(selected_risks)]

    # [4] ê²€ìƒ‰ì–´ í•„í„°
    if search_query:
        filtered_df = filtered_df[filtered_df['content'].str.contains(search_query, na=False)]

    # [5] ì •ë ¬
    risk_sort_order = {"HIGH": 0, "MEDIUM": 1, "LOW": 2, "NONE": 3}
    filtered_df['sort_key'] = filtered_df['risk_level_final'].map(risk_sort_order)
    filtered_df = filtered_df.sort_values(by='sort_key')

    # --------------------------------------------------------------------------
    # 5. ë©”ì¸ ëŒ€ì‹œë³´ë“œ
    # --------------------------------------------------------------------------
    
    # ìš”ì•½ ì •ë³´ í…ìŠ¤íŠ¸ ìƒì„±
    filter_info = []
    if selected_industry != "ì „ì²´ ë³´ê¸°": filter_info.append(f"ì—…ì¢…: {selected_industry}")
    if selected_equipment: filter_info.append(f"ì„¤ë¹„: {', '.join(selected_equipment)}")
    
    info_text = " / ".join(filter_info) if filter_info else "ì „ì²´ ë²•ë ¹"
    
    st.info(f"ğŸ“‹ **{info_text}** ê¸°ì¤€ ë¶„ì„ ê²°ê³¼ (ì´ {len(filtered_df)}ê±´)")

    m1, m2, m3 = st.columns(3)
    high_count = len(filtered_df[filtered_df['risk_level_final']=='HIGH'])
    med_count = len(filtered_df[filtered_df['risk_level_final']=='MEDIUM'])
    
    m1.metric("ğŸ”´ ì¹˜ëª…ì  ìœ„í—˜", f"{high_count}ê±´")
    m2.metric("ğŸŸ  ì£¼ìš” ê´€ë¦¬ ëŒ€ìƒ", f"{med_count}ê±´")
    m3.metric("ğŸŸ¢ ì¼ë°˜ ì¤€ìˆ˜ ì‚¬í•­", f"{len(filtered_df)-high_count-med_count}ê±´")
    
    st.divider()

  # --------------------------------------------------------------------------
    # [ìˆ˜ì •ë¨] í…ìŠ¤íŠ¸ í•˜ì´ë¼ì´íŒ… ë° ë°ì´í„° í´ë¦¬ë‹ í•¨ìˆ˜ (ì—ëŸ¬ ë°©ì§€ ë²„ì „)
    # --------------------------------------------------------------------------
    def clean_and_highlight(text, evidence):
        """
        ë°ì´í„° íƒ€ì…(ë¦¬ìŠ¤íŠ¸, ë¬¸ìì—´, NaN ë“±)ì— ìƒê´€ì—†ì´ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜
        """
        # 1. None ì²´í¬
        if evidence is None:
            return text, None
        
        # 2. ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ê²½ìš°ì—ë§Œ isna(NaN) ì²´í¬ (ë¦¬ìŠ¤íŠ¸ì— isna ì“°ë©´ ì—ëŸ¬ë‚¨!)
        if not isinstance(evidence, list):
            if pd.isna(evidence):
                return text, None
            if str(evidence).strip() == "":
                return text, None
        
        # 3. ë¹ˆ ë¦¬ìŠ¤íŠ¸ ì²´í¬
        if isinstance(evidence, list) and len(evidence) == 0:
            return text, None

        # 4. ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ì²˜ë¦¬ ì‹œì‘
        evidence_str = str(evidence)
        
        # ë¶ˆí•„ìš”í•œ ê¸°í˜¸ ì œê±°
        cleaned_evidence = re.sub(r"[\[\]']", "", evidence_str)
        keywords = [k.strip() for k in cleaned_evidence.split(',')]
        
        stopwords = ["í•  ìˆ˜ ìˆë‹¤", "í•˜ì—¬ì•¼ í•œë‹¤", "ìˆ˜ ìˆë‹¤", "í•œë‹¤"]
        valid_keywords = [k for k in keywords if k not in stopwords and len(k) > 1]
        
        if not valid_keywords:
            return text, None
            
        highlighted_text = text
        for k in valid_keywords:
            if k in highlighted_text:
                highlighted_text = highlighted_text.replace(k, f":red[**{k}**]")
                
        return highlighted_text, ", ".join(valid_keywords)
    
    # ë¦¬ìŠ¤íŠ¸ ì¶œë ¥
    if filtered_df.empty:
        st.warning("ì¡°ê±´ì— ë§ëŠ” ë²•ë¥  ì¡°í•­ì´ ì—†ìŠµë‹ˆë‹¤.")
        if selected_equipment:
            st.caption("ğŸ’¡ íŒ: ì„ íƒí•˜ì‹  ì„¤ë¹„ ê´€ë ¨ í‚¤ì›Œë“œê°€ ë²•ë ¹ ë³¸ë¬¸ì— ëª…ì‹œë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        for idx, row in filtered_df.iterrows():
            risk = row['risk_level_final']
            icon = "ğŸ”´" if risk == "HIGH" else "ğŸŸ " if risk == "MEDIUM" else "ğŸŸ¢"

            law_name = row.get('law_name', '')
            article_no = row.get('article_no', '?')
            title = row['metadata'].get('title', '') if isinstance(row.get('metadata'), dict) else ""

            expander_title = f"{icon} **[{law_name}] ì œ{article_no}ì¡° {title}**"
            
            with st.expander(expander_title):
                final_content, valid_evidence = clean_and_highlight(row['content'], row.get('risk_evidence', ''))
                
                st.markdown(final_content)
                
                if valid_evidence:
                    st.caption(f"ğŸ” **AI ë¦¬ìŠ¤í¬ ê°ì§€:** `{valid_evidence}`")
                
                st.markdown("---")
                c1, c2 = st.columns(2)
                c1.caption(f"ID: {row['node_id']}")
                if row.get('risk_from_penalties_level'):
                    c2.caption(f"âš ï¸ **ì²˜ë²Œ ì¡°í•­ ì—°ê²°ë¨**")

else:
    st.error("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆê±°ë‚˜ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")